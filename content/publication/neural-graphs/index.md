---
title: "Graph Neural Networks for Learning Equivariant Representations of Neural Networks"

# Authors
# If you created a profile for a user (e.g. the default `admin` user), write the username (folder name) here
# and it will be replaced with their full name and linked to their profile.
authors:
- adminstar
- Boris Knyazev
- Yan Zhang
- Yunlu Chen
- Gertjan J. Burghouts
- Efstratios Gavves
- Cees G. M. Snoek
- David W. Zhang*

# Author notes (optional)
author_notes:
- University of Amsterdam
- Samsung - SAIT AI Lab
- Samsung - SAIT AI Lab
- University of Amsterdam
- TNO
- University of Amsterdam
- University of Amsterdam
- University of Amsterdam

date: "2024-01-01T00:00:00Z"
doi: ""

# Schedule page publish date (NOT publication's date).
publishDate: "2024-01-01T00:00:00Z"

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["1"]

# Publication name and optional abbreviated publication name.
publication: In 12th International Conference on Learning Representations, ICLR 2024

publication_short: In ICLR, 2024*

abstract: Neural networks that process the parameters of other neural networks find applications in domains as diverse as classifying implicit neural representations, generating neural network weights, and predicting generalization errors. However, existing approaches either overlook the inherent permutation symmetry in the neural network or rely on intricate weight-sharing patterns to achieve equivariance, while ignoring the impact of the network architecture itself. In this work, we propose to represent neural networks as computational graphs of parameters, which allows us to harness powerful graph neural networks and transformers that preserve permutation symmetry. Consequently, our approach enables a single model to encode neural computational graphs with diverse architectures. We showcase the effectiveness of our method on a wide range of tasks, including classification and editing of implicit neural representations, predicting generalization performance, and learning to optimize, while consistently outperforming state-of-the-art methods.

# Summary. An optional shortened abstract.
summary: Graph Neural Networks for Learning Equivariant Representations of Neural Networks

tags: []

# Display this page in the Featured widget?
featured: true

# Custom links (uncomment lines below)
links:
- name: arXiv
  url: https://arxiv.org/abs/2403.12143
- name: OpenReview
  url: https://openreview.net/forum?id=oO6FsMyDBt

url_pdf: 'publication/neural-graphs/neural_graphs_iclr_2024.pdf'
url_code: 'https://github.com/mkofinas/neural-graphs'
url_dataset: ''
url_poster: 'neural_graphs_iclr_2024_poster.pdf'
url_project: ''
url_slides: 'neural_graphs_iclr_2024_oral.pdf'
url_source: ''
url_video: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
image:
  caption: 'Graph Neural Networks for Learning Equivariant Representations of Neural Networks'
  focal_point: ""
  preview_only: false
---
